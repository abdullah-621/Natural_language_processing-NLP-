{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b9c4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "867e2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00f809",
   "metadata": {},
   "source": [
    "### Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1cc0ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b262d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e21a8",
   "metadata": {},
   "source": [
    "### Remove HTML tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b02f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html(text):\n",
    "  pattern = re.compile(r'<.*?>')\n",
    "  return pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4adb3904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9926d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99fc44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af7691fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5594db",
   "metadata": {},
   "source": [
    "### Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc56a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "  pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "  return pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9a333cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visit  or  for more info'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Visit https://example.com or www.google.com for more info\"\n",
    "remove_url(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c0c3c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdullah  Al Masum\n",
      "Abdullah AL  Noman\n",
      "Shafi \n",
      "Kalam boss\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Abdullah http://example.com Al Masum\"\n",
    "print(remove_url(text=text1))\n",
    "\n",
    "text2 = \"Abdullah AL https://example.com/page?id=12 Noman\"\n",
    "print(remove_url(text=text2))\n",
    "\n",
    "text3 = \"Shafi www.example.com\"\n",
    "print(remove_url(text=text3))\n",
    "\n",
    "text4 = \"Kalam bosshttps://bit.ly/xyz\"\n",
    "print(remove_url(text=text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523aa223",
   "metadata": {},
   "source": [
    "### Remove Puntuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "046ac466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "03812d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "  return re.sub(r'[^\\w\\s]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251aa12c",
   "metadata": {},
   "source": [
    "### time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "523494f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you NLP ML  AI \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.141239166259766"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "text = \"Hello!!! How are you? NLP, ML & AI :)\"\n",
    "print(remove_punctuation(text))\n",
    "\n",
    "time1 = time.time() - start\n",
    "time1*50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7773e",
   "metadata": {},
   "source": [
    "#### Alternative way (Python built-in ‚Äì no regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e57cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "  return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9cf7efa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0fdb6bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you NLP ML  AI \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.281272888183594"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "text = \"Hello!!! How are you? NLP, ML & AI :)\"\n",
    "print(remove_punctuation(text))\n",
    "\n",
    "time2 = time.time() - start\n",
    "time2*50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6df53",
   "metadata": {},
   "source": [
    "### chat word trantments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0e2fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"ADIH\": \"Another Day In Hell\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"BAE\": \"Before Anyone Else\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRUH\": \"Bro\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BSAAW\": \"Big Smile And A Wink\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"BWL\": \"Bursting With Laughter\",\n",
    "    \"CSL\": \"Can‚Äôt Stop Laughing\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"DM\": \"Direct Message\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FIMH\": \"Forever In My Heart\",\n",
    "    \"FOMO\": \"Fear Of Missing Out\",\n",
    "    \"FR\": \"For Real\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYP\": \"For You Page\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GOAT\": \"Greatest Of All Time\",\n",
    "    \"GR8\": \"Great\",\n",
    "    \"HBD\": \"Happy Birthday\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek You\",\n",
    "    \"IDC\": \"I Don‚Äôt Care\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"IFYP\": \"I Feel Your Pain\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"ILY\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest Opinion\",\n",
    "    \"IMU\": \"I Miss You\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"IYKYK\": \"If You Know, You Know\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"L\": \"Loss\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMK\": \"Let Me Know\",\n",
    "    \"LMAO\": \"Laughing My Ass Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"MFW\": \"My Face When\",\n",
    "    \"MID\": \"Mediocre\",\n",
    "    \"MRW\": \"My Reaction When\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"NVM\": \"Never Mind\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"NPC\": \"Non-Player Character\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"OP\": \"Overpowered\",\n",
    "    \"PITA\": \"Pain In The Ass\",\n",
    "    \"POV\": \"Point Of View\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My Ass Off\",\n",
    "    \"RN\": \"Right Now\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your Sex And Age\",\n",
    "    \"SUS\": \"Suspicious\",\n",
    "    \"TBH\": \"To Be Honest\",\n",
    "    \"TFW\": \"That Feeling When\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TIME\": \"Tears In My Eyes\",\n",
    "    \"TLDR\": \"Too Long, Didn‚Äôt Read\",\n",
    "    \"TNTL\": \"Trying Not To Laugh\",\n",
    "    \"TTFN\": \"Ta-Ta For Now\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    'R' : 'are',\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"W\": \"Win\",\n",
    "    \"W8\": \"Wait\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The Fuck\",\n",
    "    \"WTG\": \"Way To Go\",\n",
    "    \"WUF\": \"Where Are You From\",\n",
    "    \"WYD\": \"What You Doing\",\n",
    "    \"WYWH\": \"Wish You Were Here\",\n",
    "    \"ZZZ\": \"Sleeping, Bored, Tired\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b48447b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_chat_words(text, chat_words):\n",
    "  new_text = []\n",
    "  for w in text.split():\n",
    "    if w.upper() in chat_words:\n",
    "      new_text.append(chat_words[w.upper()])\n",
    "    else:\n",
    "      new_text.append(w)\n",
    "  return ' '.join(new_text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6af3d1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you are amazing by the way i don't know why laughing out loud\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"u r amazing btw idk why lol\"\n",
    "replace_chat_words(text, chat_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93347595",
   "metadata": {},
   "source": [
    "### Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "92580533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4be3e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75146edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spelling_correction(text):\n",
    "  textblb = TextBlob(text)\n",
    "  return textblb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "67a130eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this sentence have spelling error'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this sentene hase speling eror\"\n",
    "Spelling_correction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6aac17",
   "metadata": {},
   "source": [
    "### StopWord remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fed1815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8f9b5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d75fae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4b9bb8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0a06bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  new_text = []\n",
    "\n",
    "  for word in text.split():\n",
    "    if word in stopwords.words('english'):\n",
    "      new_text.append('')\n",
    "    else:\n",
    "      new_text.append(word)\n",
    "\n",
    "  # x = new_text[:]\n",
    "  # new_text.clear()\n",
    "\n",
    "  return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a870a4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This   simple sentence   stopwords.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a simple sentence with some stopwords.\"\n",
    "\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d90b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.review = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "40ae5e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f717f",
   "metadata": {},
   "source": [
    "### Emoji handeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "133f526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "  emoji_pattern = re.compile(\n",
    "    \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons üòÅ-üò∑\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs üåàüçî\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols üöÄüõ≥\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags üá∫üá∏üáßüá©\n",
    "    \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    u\"\\U00002700-\\U000027BF\"  # dingbats\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols\n",
    "    u\"\\U00002600-\\U000026FF\"  # Misc symbols\n",
    "    \"]+\", flags=re.UNICODE\n",
    ")\n",
    "  \n",
    "  return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4751c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ! I love NLP Ô∏è'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello üòÅ! I love NLP ‚ù§Ô∏èüöÄüåà\"\n",
    "remove_emoji(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5dc0bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "048b1d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello :beaming_face_with_smiling_eyes:! I love NLP :red_heart::rocket::rainbow:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "text = \"Hello üòÅ! I love NLP ‚ù§Ô∏èüöÄüåà\"\n",
    "print(emoji.demojize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1643ee",
   "metadata": {},
   "source": [
    "### Tokonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be60300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "575a339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\ABDULLAH AL\n",
      "[nltk_data]     MASUM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')  # This will take a while but ensures everything is downloaded\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a22fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'machine', 'learning', 'and', 'deep', 'learning']\n"
     ]
    }
   ],
   "source": [
    "sen = \"I love machine learning and deep learning\"\n",
    "words = word_tokenize(sen)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4031b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "snetences = \"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\"\n",
    "\n",
    "sen = sent_tokenize(snetences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "54d9a209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\",\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f3032",
   "metadata": {},
   "source": [
    "#### Use Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "73368f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3603532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1b301855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"I love ML and DL! a.a.masum621@gmail.com\"\n",
    "sent2 = \"I love python and DS\"\n",
    "sent3 = \"Currently i learn NLP\"\n",
    "sent4 = \"After finish this course I will be great ML engineers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f1917699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6bb4aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(sent1)\n",
    "doc2 = nlp(sent2)\n",
    "doc3 = nlp(sent3)\n",
    "doc4 = nlp(sent4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fa8b3b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8e277258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "love\n",
      "ML\n",
      "and\n",
      "DL\n",
      "!\n",
      "a.a.masum621@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60a5c9",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "269bfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7aadff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_word(text):\n",
    "  return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c67e5b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_word(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a039cc",
   "metadata": {},
   "source": [
    "### Lammatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98bde166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ABDULLAH AL\n",
      "[nltk_data]     MASUM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "be\n",
      "run\n",
      "and\n",
      "eat\n",
      "at\n",
      "same\n",
      "time\n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizaer = WordNetLemmatizer()\n",
    "\n",
    "sen = \"He was running and eating at same time\"\n",
    "\n",
    "# sen_split = sen.split()\n",
    "sen_split = nltk.word_tokenize(sen)\n",
    "\n",
    "for word in sen_split:\n",
    "  print(wordnet_lemmatizaer.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'was', 'running', '!', 'and', 'eating', 'at', 'same', 'time', '.']\n",
      "He\n",
      "be\n",
      "run\n",
      "and\n",
      "eat\n",
      "at\n",
      "same\n",
      "time\n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizaer = WordNetLemmatizer()\n",
    "\n",
    "sen = \"He was running! and eating at same time.\"\n",
    "\n",
    "punctuation = \"?:!.,;\"\n",
    "\n",
    "# sen_split = sen.split()\n",
    "sen_split = nltk.word_tokenize(sen)\n",
    "\n",
    "print(sen_split)\n",
    "\n",
    "for word in sen_split:\n",
    "  if word in punctuation:\n",
    "    sen_split.remove(word)\n",
    "\n",
    "for word in sen_split:\n",
    "  print(wordnet_lemmatizaer.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd8d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
