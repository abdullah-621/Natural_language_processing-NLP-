{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a29fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1887817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "# !pip install gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b9e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of 'learning':\n",
      " [-1.06417970e-03  4.61772666e-04  1.01990532e-02  1.80347376e-02\n",
      " -1.86461825e-02 -1.42584192e-02  1.29590398e-02  1.80226769e-02\n",
      " -1.00531587e-02 -7.54957274e-03  1.47702079e-02 -3.07855476e-03\n",
      " -9.07690544e-03  1.31388931e-02 -9.71754733e-03 -3.62283597e-03\n",
      "  5.79606555e-03  2.02882406e-03 -1.66096296e-02 -1.89468749e-02\n",
      "  1.46633051e-02  1.01255635e-02  1.35620562e-02  1.53882208e-03\n",
      "  1.27362479e-02 -6.83639152e-03 -1.92245294e-03  1.15869725e-02\n",
      " -1.50872357e-02 -7.86963850e-03 -1.50539009e-02 -1.86006317e-03\n",
      "  1.91195384e-02 -1.46809928e-02 -4.67411568e-03 -3.89644178e-03\n",
      "  1.62153952e-02 -1.18744615e-02  1.22111029e-04 -9.54135507e-03\n",
      " -1.92500353e-02  1.00153079e-02 -1.75626203e-02 -8.81946273e-03\n",
      " -4.80665949e-05 -5.66069270e-04 -1.53056365e-02  1.92347523e-02\n",
      "  9.96814854e-03  1.84887405e-02]\n",
      "\n",
      "Similarity between machine & deep: -0.15466388\n",
      "\n",
      "Words similar to 'learning':\n",
      "[('fun', 0.13314922153949738), ('deep', 0.12766702473163605), ('is', 0.04267624765634537), ('i', 0.013254021294414997), ('machine', -0.01303892768919468), ('powerful', -0.05942307040095329), ('love', -0.11653497070074081)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Step 1: Training data (tokenized sentences)\n",
    "sentences = [\n",
    "    [\"i\", \"love\", \"machine\", \"learning\"],\n",
    "    [\"i\", \"love\", \"deep\", \"learning\"],\n",
    "    [\"machine\", \"learning\", \"is\", \"fun\"],\n",
    "    [\"deep\", \"learning\", \"is\", \"powerful\"]\n",
    "]\n",
    "\n",
    "# Step 2: Train Word2Vec (CBOW)\n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=50,   # embedding dimension\n",
    "    window=2,         # context window\n",
    "    min_count=1,      # ignore words with freq < 1\n",
    "    sg=0,             # sg=0 â†’ CBOW (IMPORTANT)\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "# Step 3: Get word vector\n",
    "vector = model.wv[\"learning\"]\n",
    "print(\"Vector of 'learning':\\n\", vector)\n",
    "\n",
    "# Step 4: Similarity check\n",
    "similarity = model.wv.similarity(\"machine\", \"deep\")\n",
    "print(\"\\nSimilarity between machine & deep:\", similarity)\n",
    "\n",
    "# Step 5: Most similar words\n",
    "print(\"\\nWords similar to 'learning':\")\n",
    "print(model.wv.most_similar(\"learning\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bedce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: gensim\n"
     ]
    }
   ],
   "source": [
    "!pip show gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a6c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
