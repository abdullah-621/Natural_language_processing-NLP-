{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "015141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdc552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d39f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\T\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\T\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\T\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\T\"? A raw string is also an option.\n",
      "C:\\Users\\ABDULLAH AL MASUM\\AppData\\Local\\Temp\\ipykernel_26548\\3050363139.py:1: SyntaxWarning: \"\\T\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\T\"? A raw string is also an option.\n",
      "  df = pd.read_csv(\"..\\Text_Representation\\Conunter_TF_IDF\\IMDB Dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\Text_Representation\\Conunter_TF_IDF\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "283b4e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b017a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c70e4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c8629aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ABDULLAH AL\n",
      "[nltk_data]     MASUM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "225540a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"ADIH\": \"Another Day In Hell\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"BAE\": \"Before Anyone Else\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRUH\": \"Bro\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BSAAW\": \"Big Smile And A Wink\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"BWL\": \"Bursting With Laughter\",\n",
    "    \"CSL\": \"Can’t Stop Laughing\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"DM\": \"Direct Message\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FIMH\": \"Forever In My Heart\",\n",
    "    \"FOMO\": \"Fear Of Missing Out\",\n",
    "    \"FR\": \"For Real\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYP\": \"For You Page\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GOAT\": \"Greatest Of All Time\",\n",
    "    \"GR8\": \"Great\",\n",
    "    \"HBD\": \"Happy Birthday\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek You\",\n",
    "    \"IDC\": \"I Don’t Care\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"IFYP\": \"I Feel Your Pain\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"ILY\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest Opinion\",\n",
    "    \"IMU\": \"I Miss You\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"IYKYK\": \"If You Know, You Know\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"L\": \"Loss\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMK\": \"Let Me Know\",\n",
    "    \"LMAO\": \"Laughing My Ass Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"MFW\": \"My Face When\",\n",
    "    \"MID\": \"Mediocre\",\n",
    "    \"MRW\": \"My Reaction When\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"NVM\": \"Never Mind\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"NPC\": \"Non-Player Character\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"OP\": \"Overpowered\",\n",
    "    \"PITA\": \"Pain In The Ass\",\n",
    "    \"POV\": \"Point Of View\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My Ass Off\",\n",
    "    \"RN\": \"Right Now\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your Sex And Age\",\n",
    "    \"SUS\": \"Suspicious\",\n",
    "    \"TBH\": \"To Be Honest\",\n",
    "    \"TFW\": \"That Feeling When\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TIME\": \"Tears In My Eyes\",\n",
    "    \"TLDR\": \"Too Long, Didn’t Read\",\n",
    "    \"TNTL\": \"Trying Not To Laugh\",\n",
    "    \"TTFN\": \"Ta-Ta For Now\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    'R' : 'are',\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"W\": \"Win\",\n",
    "    \"W8\": \"Wait\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The Fuck\",\n",
    "    \"WTG\": \"Way To Go\",\n",
    "    \"WUF\": \"Where Are You From\",\n",
    "    \"WYD\": \"What You Doing\",\n",
    "    \"WYWH\": \"Wish You Were Here\",\n",
    "    \"ZZZ\": \"Sleeping, Bored, Tired\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b3a1505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba80ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_words_process(text):\n",
    "  new_text = []\n",
    "  for word in text.split():\n",
    "    if word.upper() in chat_words:\n",
    "      new_text.append(chat_words[word.upper()])\n",
    "    else:\n",
    "      new_text.append(word)\n",
    "  \n",
    "  return \" \".join(new_text).lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c3cf8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textblob import TextBlob\n",
    "def spelling_correction(text):\n",
    "  textblb = TextBlob(text)\n",
    "  return textblb.correct().string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ed069733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_procecess(text):\n",
    "\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'<.*?>', \" \", text)\n",
    "  text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
    "  text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "  # Chat words\n",
    "  text = chat_words_process(text)\n",
    "\n",
    "  # Spelling correction (optional, slow)\n",
    "  # text = spelling_correction(text)\n",
    "\n",
    "  # Tokenization\n",
    "  token = word_tokenize(text)\n",
    "\n",
    "  # Lemmatization\n",
    "  text = [lemma.lemmatize(w, pos = 'v') for w in token] \n",
    "\n",
    "  # Stopword removal\n",
    "  text = [w for w in text if w not in stop_words] # stop word remove\n",
    "\n",
    "  return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4db4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children play better game aslo win\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The children are playing better games and aslo W\"\n",
    "print(Text_procecess(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67dc4b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children play better game\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The children are playing better games\"\n",
    "print(Text_procecess(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_comment'] = df['review'].apply(Text_procecess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c407ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mention watch 1 oz episode youll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production film technique una...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>think wonderful way spend tear eye hot summer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family little boy jake think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love tear eye money visually st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                       clean_comment  \n",
       "0  one reviewers mention watch 1 oz episode youll...  \n",
       "1  wonderful little production film technique una...  \n",
       "2  think wonderful way spend tear eye hot summer ...  \n",
       "3  basically theres family little boy jake think ...  \n",
       "4  petter matteis love tear eye money visually st...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "09d87ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e16f244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c851b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6cac8679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(50000, 10000))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6c9f25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le  = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bc964c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = le.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c6f1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ed2e7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "76f25846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb146436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b96f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4361,  470],\n",
       "       [ 600, 4569]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b73f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "  cleaned = Text_procecess(text)\n",
    "  vector = tfidf.transform([cleaned]) # TF-IDF wants list\n",
    "  prediction = model.predict(vector)[0]\n",
    "  return le.inverse_transform([prediction])[0] # convert \n",
    "\n",
    "# LabelEncoder.inverse_transform converts numeric labels predicted by the model back to their original categorical string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9856dc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"Worst movie ever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f7a64b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9071d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Text_procecess(\"This movie is amazing\")\n",
    "v = tfidf.transform([c])\n",
    "p = model.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e620fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], shape=(1, 10000))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2250ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABDULLAH AL MASUM\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:161: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([p])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525fae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
